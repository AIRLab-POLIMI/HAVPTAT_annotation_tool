<!---
[![Anaconda-Server Badge](https://anaconda.org/bsteubing/activity-browser/badges/version.svg)](https://anaconda.org/bsteubing/activity-browser)
[![Anaconda-Server Badge](https://anaconda.org/bsteubing/activity-browser/badges/downloads.svg)](https://anaconda.org/bsteubing/activity-browser)
[![Pull request tests](https://github.com/LCA-ActivityBrowser/activity-browser/actions/workflows/main.yaml/badge.svg)](https://github.com/LCA-ActivityBrowser/activity-browser/actions/workflows/main.yaml)
[![Coverage Status](https://coveralls.io/repos/github/LCA-ActivityBrowser/activity-browser/badge.svg?branch=master)](https://coveralls.io/github/LCA-ActivityBrowser/activity-browser?branch=master)
-->

# HAVPTAT: A Human Activity Video Pose Tracking Annotation Tool

<img src=".\src\windows.png"/>

<img src=".\src\feature.png" width=100%/>

Human Activity Video Pose Tracking Annotation Tool (HAVPTAT) is a new semi-automatic annotation software.
It can automatically detect and track multiple people and their pose in the video to improve work efficiency. HAVPTAT also provides the dynamical visualization of human pose, bounding boxes, person tracking ID, and possible prediction results together. The lightweight software can be launched in a few seconds and easily distributed. Its ease of use will allow non-professionals to get started quickly. This software will accelerate the development of human activity recognition models and service robots.

## Highlights

-	A novel human activity annotation software
-	Automatic human pose detection and tracking in video
-	Lightweight and easy to use


## Demo
Please watch our video on [YouTube](https://youtu.be/iTE9zTa5Bdk) to see how to use HAVPTAT.


## Contents
- [Prerequisites](#prerequisites)
- [Quickstart](#Quickstart)
- [Getting started](#getting-started)
- [Build from source](#build-from-source)
- [Contributing](#contributing)
- [Authors](#authors)
- [License](#license)
- [Citation](#citation)

## Prerequisites

- Operating System: `MS Windows`

- Please choose one of the method to download `FFMPEG` (for video manipulation):

    - From our [OneDrive](https://polimi365-my.sharepoint.com/:f:/g/personal/10381116_polimi_it/Ej2P2g1nCUFAkR0lqXZ5fDAB6DVbMRL30Q2_bPT59j38hw?e=A7eE2b) link (Highly recommended)

    - (OR) From the FFPMEG official website (we do not guarentee the correct functionality): 
        https://www.ffmpeg.org/download.html and rename main folder to `"ffmpeg"`
        

- Then save FFMPEG program folder into root path of disk `C:\`, structure of app folder like `C:\ffmpeg\bin\ffmpeg.exe` ...

### Recommended folder structure (but not necesary)
To automatically fetch the imported video file's corresponding JSON file generated by OpenPifpaf (without annotated), we suggest to put files following the structure tree below.
The name of video and JSON should be the same, i.e., `XXX.mp4` and `XXX.json`

Create two folders:
- "video": folder of video file(s) to be annotated.
- "json_input": folder of raw JSON format file(s) generated by OpenPifPaf.
    
```
[YOUR_HAVPTAT_PROJECT_ROOT_PATH]
│   
│
└─── video
│     │   VID_20210226_160149.mp4
│     │   VID_20210226_162758.mp4
│     │   ...
│     └──────
│   
│   
└─── json_input
        │   VID_20210226_160149.json
        │   VID_20210226_162758.json
        │   ...
        └──────

```

### Otherwise, the manual locating JSON file is also allowed. 

    


## Quickstart

If you want to only use HAVPTAT, download the folder from [OneDrive](https://polimi365-my.sharepoint.com/:f:/g/personal/10381116_polimi_it/Et0jJlVBaAJGgvIbFmddRmABmXZjGws3PPo_bkugRU7rkw?e=bxZMxW) link.

Then simply run `VideoLabelTool.exe` and the application will open.


## Getting started

We provide:
-  a demo video on [YouTube](https://www.youtube.com/channel/UCsyySKrzEMsRFsWW1Oz-6aA/) showing how to use HAVPTAT.
-  a demo resource (.mp4 and .json) to try on [OneDrive](https://polimi365-my.sharepoint.com/:f:/g/personal/10381116_polimi_it/EtYT0axMQ1xKsGMuwR5NmBsBXyhtivd67TTnq9i5n2QNCg?e=MdtiEx).

### Workflow

- Click from menu `[File] - [Open]` to open a video to be annotated.
- Click `[Import]` to locate the video's JSON format file generated by OpenPifPaf .
- Start to annotate, click a bounding box of a person and then click the action button to associate the action label.
- Click `[Export]` when the annotation work is finished. 
  The annotated JSON file will be saved in the parent folder of the selected video. 
  E.g., if the video is stored in a folder `.\video\XXX.mp4`, the annotated file will be stored in `.\json_output\action__XXX.json`.
- (Option) If you want to change a segment of frames:
  - click `interpolation mode` to activate the interpolation functionality
  - set the numbers of the start and the end of the frames, 
  - click the bounding box of a target person
  - click an action label

---

## Build from source

Continue to read this section **ONLY IF** you want to build the code from source and/or for development purpose. Otherwise, please skip this section.

Clone the project to your file system.

```bash
git clone https://github.com/AIRLab-POLIMI/HAVPTAT_annotation_tool.git
```


- Download `MS Visual Studio 2019 or 2022` version for *MS Windows* from the official website: https://visualstudio.microsoft.com/downloads/
- Open the cloned HAVTPAT project and open `.\VideoLabelToolSol.sln`


## Contributing

**Your contribution counts! The HAVPTAT is a community project.**

<!---
If you have ideas for improvements to the code or documentation or want to propose new features, please take a look at our [contributing guidelines](CONTRIBUTING.md) and open issues and/or pull-requests.
If you experience problems or are suffering from a specific bug, please [raise an issue](https://github.com/LCA-ActivityBrowser/activity-browser/issues) here on github.
-->

If you have ideas for improvements to the code or documentation or want to propose new features, please open issues and/or pull-requests.

If you experience problems or are suffering from a specific bug, please [raise an issue](https://github.com/AIRLab-POLIMI/HAVPTAT_annotation_tool/issues) here on GitHub.

## Authors
- Hao Quan (hao.quan@polimi.it)
- Andrea Bonarini (andrea.bonarini@polimi.it)


## License
This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published
by the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.


## Citation

Please cite this work if you find it useful:.

    @article{,
        title = {},
        journal = {Software Impacts},
        volume = {},
        pages = {},
        year = {2022},
        issn = {},
        doi = {},
        url = {},
        author = {},
        keywords = {}
    }